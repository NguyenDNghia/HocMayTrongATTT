{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/mcflinta/Dataset_ML__Newbie.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_DM6_cQ4qX_8",
        "outputId": "5a1cc3f5-57f5-4506-9a4d-42d21d226430"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Dataset_ML__Newbie'...\n",
            "remote: Enumerating objects: 18, done.\u001b[K\n",
            "remote: Counting objects: 100% (18/18), done.\u001b[K\n",
            "remote: Compressing objects: 100% (14/14), done.\u001b[K\n",
            "remote: Total 18 (delta 1), reused 15 (delta 1), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (18/18), 10.79 MiB | 11.72 MiB/s, done.\n",
            "Resolving deltas: 100% (1/1), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_file_path = '/content/Dataset_ML__Newbie/Lab_2/ds_lab2.zip'\n",
        "extract_file_path = '/content/'\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "  zip_ref.extractall(extract_file_path)"
      ],
      "metadata": {
        "id": "N3uA4Gj8rM90"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pefile"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQRlmGkq6DkY",
        "outputId": "4e355b48-62b8-4826-c802-bdf2c35ee2d7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pefile\n",
            "  Downloading pefile-2023.2.7-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.8/71.8 kB\u001b[0m \u001b[31m596.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pefile\n",
            "Successfully installed pefile-2023.2.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Featurizing the PE header"
      ],
      "metadata": {
        "id": "ePgbpRTS7ZVV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Câu 4: Làm các câu truy vấn về Python và Powershell"
      ],
      "metadata": {
        "id": "VDT_RVgonWi_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyGitHub"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HgJvyohndrW",
        "outputId": "b8995a5b-e8d9-46c2-9410-8e922562beb3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyGitHub\n",
            "  Downloading PyGithub-2.3.0-py3-none-any.whl (354 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m354.4/354.4 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pynacl>=1.4.0 (from PyGitHub)\n",
            "  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m856.7/856.7 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from PyGitHub) (2.31.0)\n",
            "Collecting pyjwt[crypto]>=2.4.0 (from PyGitHub)\n",
            "  Downloading PyJWT-2.8.0-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from PyGitHub) (4.11.0)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from PyGitHub) (2.0.7)\n",
            "Collecting Deprecated (from PyGitHub)\n",
            "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: cryptography>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from pyjwt[crypto]>=2.4.0->PyGitHub) (42.0.5)\n",
            "Requirement already satisfied: cffi>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from pynacl>=1.4.0->PyGitHub) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.14.0->PyGitHub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.14.0->PyGitHub) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.14.0->PyGitHub) (2024.2.2)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from Deprecated->PyGitHub) (1.14.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.4.1->pynacl>=1.4.0->PyGitHub) (2.22)\n",
            "Installing collected packages: pyjwt, Deprecated, pynacl, PyGitHub\n",
            "  Attempting uninstall: pyjwt\n",
            "    Found existing installation: PyJWT 2.3.0\n",
            "    Uninstalling PyJWT-2.3.0:\n",
            "      Successfully uninstalled PyJWT-2.3.0\n",
            "Successfully installed Deprecated-1.2.14 PyGitHub-2.3.0 pyjwt-2.8.0 pynacl-1.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from github import Github\n",
        "import base64"
      ],
      "metadata": {
        "id": "ZnfouO2tnhzE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "username = \"mcflinta\"\n",
        "password = \"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\"\n",
        "target_dir_powershell = \"/content/PowerShellSamples\"\n",
        "target_dir_python = \"/content/PythonSamples\"\n",
        "g = Github(username, password)\n",
        "repositories = g.search_repositories(query=\"language:PowerShell language:Python\")\n",
        "n = 9\n",
        "i = 0"
      ],
      "metadata": {
        "id": "iUN6hXU_nrii"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for repo in repositories:\n",
        "  reponame = repo.name\n",
        "  target_dir_of_repo_powershell = target_dir_powershell + \"\\\\\" + reponame\n",
        "  target_dir_of_repo_python = target_dir_python + \"\\\\\" + reponame\n",
        "\n",
        "  print(reponame)\n",
        "  try:\n",
        "    i += 1\n",
        "    contents = repo.get_contents(\"\")\n",
        "    while len(contents) > 1:\n",
        "      file_content = contents.pop(0)\n",
        "      if file_content.type == \"dir\":\n",
        "        contents.extend(repo.get_contents(file_content.path))\n",
        "      else:\n",
        "        st = str(file_content)\n",
        "        filename = st.split('\"')[1].split('\"')[0]\n",
        "        extension = filename.split(\".\")[-1]\n",
        "        if extension == \"ps1\":\n",
        "          if not os.path.exists(target_dir_of_repo_powershell):\n",
        "            os.mkdir(target_dir_of_repo_powershell)\n",
        "          filecontents = repo.get_contents(file_content.path)\n",
        "          file_data = base64.b64decode(filecontents.content)\n",
        "          filename = filename.split(\"/\")[-1]\n",
        "          file_out = open(target_dir_of_repo_powershell + \"/\" + filename, \"wb\")\n",
        "          file_out.write(file_data)\n",
        "        elif extension == \"py\":\n",
        "          if not os.path.exists(target_dir_of_repo_python):\n",
        "            os.mkdir(target_dir_of_repo_python)\n",
        "          filecontents = repo.get_contents(file_content.path)\n",
        "          file_data = base64.b64decode(filecontents.content)\n",
        "          filename = filename.split(\"/\")[-1]\n",
        "          file_out = open(target_dir_of_repo_python + \"/\" + filename, \"wb\")\n",
        "          file_out.write(file_data)\n",
        "\n",
        "  except:\n",
        "    pass\n",
        "  if i == n:\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrYP_rFV0syf",
        "outputId": "3a3b6457-2342-4c28-ca58-c3db80d32326"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "public-apis\n",
            "system-design-primer\n",
            "react\n",
            "awesome-python\n",
            "javascript-algorithms\n",
            "Python\n",
            "bootstrap\n",
            "AutoGPT\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Request GET /repos/Significant-Gravitas/AutoGPT/contents/benchmark/reports/smol-developer/folder63_08-15-16-42 failed with 403: Forbidden\n",
            "INFO:github.GithubRetry:Request GET /repos/Significant-Gravitas/AutoGPT/contents/benchmark/reports/smol-developer/folder63_08-15-16-42 failed with 403: Forbidden\n",
            "Setting next backoff to 1237.172187s\n",
            "INFO:github.GithubRetry:Setting next backoff to 1237.172187s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python-100-Days\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Request GET /repos/jackfrued/Python-100-Days/contents/ failed with 403: Forbidden\n",
            "INFO:github.GithubRetry:Request GET /repos/jackfrued/Python-100-Days/contents/ failed with 403: Forbidden\n",
            "Setting next backoff to 307.364148s\n",
            "INFO:github.GithubRetry:Setting next backoff to 307.364148s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Câu 8: Xây dựng trình phát hiện phần mềm độc hại bằng phân tích tĩnh"
      ],
      "metadata": {
        "id": "nDFuGEJTo8x-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bước 1: Tạo list các mẫu và gán nhãn cho chúng"
      ],
      "metadata": {
        "id": "LnbGIsD8rtL8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "directories_and_labels = [(\"/content/Benign PE Samples/\", 0),\n",
        "                          (\"/content/Malicious PE Samples/\", 1)]\n",
        "\n",
        "list_of_samples = []\n",
        "labels = []\n",
        "N_spec = 2 # N-grams"
      ],
      "metadata": {
        "id": "6blvrBRIrz2v"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for ds_path, label in directories_and_labels:\n",
        "  samples = [item for item in os.listdir(ds_path)]\n",
        "  for sample in samples:\n",
        "    file_path = os.path.join(ds_path, sample)\n",
        "    list_of_samples.append(file_path)\n",
        "    labels.append(label)"
      ],
      "metadata": {
        "id": "x9ceeaVIsd-u"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Xem 5 samples và nhẵn đầu tiên\n",
        "list_of_samples[:5], labels[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVmbAK78s89t",
        "outputId": "ac846dec-293b-4dbd-9d8c-0b248f9b721f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['/content/Benign PE Samples/IMEWDBLD.EXE',\n",
              "  '/content/Benign PE Samples/InspectVhdDialog6.2.exe',\n",
              "  '/content/Benign PE Samples/imjpuexc.exe',\n",
              "  '/content/Benign PE Samples/logoff.exe',\n",
              "  '/content/Benign PE Samples/isoburn.exe'],\n",
              " [0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Xem 5 samples và nhãn cuối cùng\n",
        "list_of_samples[(len(list_of_samples) - 5):], labels[(len(labels) - 5):]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxtY1rUHtX9e",
        "outputId": "7e30f222-a265-4bf3-90cb-3115237ab80e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['/content/Benign PE Samples/LicensingUI.exe',\n",
              "  '/content/Benign PE Samples/IMEPADSV.EXE',\n",
              "  '/content/Benign PE Samples/IMJPDCT.EXE',\n",
              "  '/content/Benign PE Samples/lpksetup.exe',\n",
              "  '/content/Malicious PE Samples/aapt.exe'],\n",
              " [0, 0, 0, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bước 2: Chia dữ liệu train và test"
      ],
      "metadata": {
        "id": "f_4Fld_gv4GW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n"
      ],
      "metadata": {
        "id": "ZEq0A9vgv87U"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "samples_train, samples_test, target_train, target_test = train_test_split(\n",
        "    list_of_samples,\n",
        "    labels,\n",
        "    test_size=0.3,\n",
        "    stratify=labels,\n",
        "    random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "napqjnZEwEO8"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bước 3: Các hàm lấy thuộc tính"
      ],
      "metadata": {
        "id": "KU-IKdcQwcn0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "from nltk import ngrams\n",
        "import numpy\n",
        "import pefile"
      ],
      "metadata": {
        "id": "2JGv0n0NwhI9"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_file(file_path):\n",
        "  with open(file_path, \"rb\") as bin_file:\n",
        "    data = bin_file.read()\n",
        "    return data"
      ],
      "metadata": {
        "id": "Z4rYMx13wlhn"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def byte_seq_to_Ngrams(byte_seq, N_par):\n",
        "  Ngrams_par = ngrams(byte_seq, N_par)\n",
        "  return list(Ngrams_par)\n"
      ],
      "metadata": {
        "id": "YpultIZtwxsC"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bin_file_to_Ngrams_count(file_path, N_par):\n",
        "  file_seq = read_file(file_path)\n",
        "  file_Ngrams = byte_seq_to_Ngrams(file_seq, N_par)\n",
        "  return collections.Counter(file_Ngrams)\n",
        ""
      ],
      "metadata": {
        "id": "VjYZKV6sw7ke"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_Ngrams_features_from_samples(sample, K1_most_freq_Ngrams_list):\n",
        "  K1 = len(K1_most_freq_Ngrams_list)\n",
        "  feature_vector = K1 * [0]\n",
        "  file_Ngrams = bin_file_to_Ngrams_count(sample, N_spec)\n",
        "  for i in range(K1):\n",
        "    feature_vector[i] = file_Ngrams[K1_most_freq_Ngrams_list[i]]\n",
        "  return feature_vector"
      ],
      "metadata": {
        "id": "Bo3cW9kHw_ce"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_imports(list_of_DLLs):\n",
        "  \"\"\" Normalize the name of the imports of a PE file. \"\"\"\n",
        "  temp = [x.decode().split(\".\")[0].lower() for x in list_of_DLLs] # View the transforming of below example\n",
        "  return \" \".join(temp)"
      ],
      "metadata": {
        "id": "_BZ9IHMMxA5G"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_imports(pe):\n",
        "  \"\"\" Get a list of the imports of a PE file \"\"\"\n",
        "  list_of_imports = []\n",
        "  for entry in pe.DIRECTORY_ENTRY_IMPORT:\n",
        "    list_of_imports.append(entry.dll)\n",
        "  return preprocess_imports(list_of_imports)"
      ],
      "metadata": {
        "id": "2aLLwAwCxCqe"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_section_names(pe):\n",
        "  \"\"\" Get a list of the section names of a PE file \"\"\"\n",
        "  list_of_sections = []\n",
        "  for sect in pe.sections:\n",
        "    normalized_name = sect.Name.decode().replace(\"\\x00\", \"\").lower()\n",
        "    list_of_sections.append(normalized_name)\n",
        "  return \"\".join(list_of_sections)"
      ],
      "metadata": {
        "id": "_DWH8q_oxEL2"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bước 4: Chọn 100 thuộc tính phổ biến với 2-grams"
      ],
      "metadata": {
        "id": "RNJX0BCSxQcj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Ngrams_count_all = collections.Counter([])\n",
        "for sample in samples_train:\n",
        "  Ngrams_count_all += bin_file_to_Ngrams_count(sample, N_spec)\n",
        "K1 = 100\n",
        "K1_most_common_Ngrams = Ngrams_count_all.most_common(K1)\n",
        "K1_most_common_Ngrams_list = [x[0] for x in K1_most_common_Ngrams]"
      ],
      "metadata": {
        "id": "NXjyzmL7xfT2"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bước 5: Trích xuất số lượng N-grams count, section names, imports và số lượng sections của mỗi mẫu trong train-test."
      ],
      "metadata": {
        "id": "PxiXwBEExmpI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "imports_corpus_train = []\n",
        "num_sect_train = []\n",
        "sect_name_train = []\n",
        "Ngram_feat_list_train = []\n",
        "\n",
        "y_train = []"
      ],
      "metadata": {
        "id": "-EpoXfj6xqps"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(samples_train)):\n",
        "  sample = samples_train[i]\n",
        "  try:\n",
        "    # Get all required parameters with predefined functions\n",
        "    Ngram_features = get_Ngrams_features_from_samples(sample, K1_most_common_Ngrams_list)\n",
        "    pe = pefile.PE(sample)\n",
        "    imports = get_imports(pe)\n",
        "    n_sections = len(pe.sections)\n",
        "    sec_names = get_section_names(pe)\n",
        "\n",
        "    # Put above value into lists\n",
        "    imports_corpus_train.append(imports)\n",
        "    num_sect_train.append(n_sections)\n",
        "    sect_name_train.append(sec_names)\n",
        "    Ngram_feat_list_train.append(Ngram_features)\n",
        "\n",
        "    # Target train\n",
        "    y_train.append(target_train[i])\n",
        "  except Exception as e:\n",
        "    print(sample + \":\")\n",
        "    print(e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8R3c65lextcE",
        "outputId": "fe2cef29-6ab8-442f-e092-ee8ff3d8d298"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Benign PE Samples/LogCollector.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/Benign PE Samples/lpq.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/Benign PE Samples/inetinfo.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/Benign PE Samples/InspectVhdDialog.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/Benign PE Samples/hvsirdpclient.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/Benign PE Samples/InetMgr6.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/Benign PE Samples/LogCollector.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/Benign PE Samples/iissetup.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/Benign PE Samples/inetinfo.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/Benign PE Samples/InetMgr.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/Benign PE Samples/hvsirpcd.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/Benign PE Samples/iisreset.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/Benign PE Samples/lpr.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/Benign PE Samples/InspectVhdDialog6.3.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/Benign PE Samples/iisrstas.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/Benign PE Samples/hvsirdpclient.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/Benign PE Samples/ldifde.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/Benign PE Samples/InetMgr.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/Benign PE Samples/InspectVhdDialog6.2.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/Benign PE Samples/lpr.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/Benign PE Samples/LxRun.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/Benign PE Samples/iisreset.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/Benign PE Samples/LxRun.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/Benign PE Samples/InetMgr.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/Benign PE Samples/iisrstas.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/Benign PE Samples/lpq.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/Benign PE Samples/iissetup.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/Benign PE Samples/ldp.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/Benign PE Samples/InspectVhdDialog.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/Benign PE Samples/hvsirpcd.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/Benign PE Samples/LogCollector.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/Benign PE Samples/lpq.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/Benign PE Samples/InspectVhdDialog.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/Benign PE Samples/lpr.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/Benign PE Samples/ldp.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/Benign PE Samples/iissetup.exe:\n",
            "'DOS Header magic not found.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bước 6: Sử dụng hàm băm tfidf để chuyển imports, section names từ văn bản thành dạng số"
      ],
      "metadata": {
        "id": "OB9kGfVqx63o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import HashingVectorizer, TfidfTransformer\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "metadata": {
        "id": "ntBDP0Sfx_3u"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imports_featurizer = Pipeline(\n",
        "    [\n",
        "        (\"vect\", HashingVectorizer(input = \"content\", ngram_range=(1,2))),\n",
        "        (\"tfidf\", TfidfTransformer(use_idf = True,)),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "SwzyXwSmyCjW"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sect_name_featurizer = Pipeline(\n",
        "    [\n",
        "        (\"vect\", HashingVectorizer(input = \"content\", ngram_range= (1,2))),\n",
        "        (\"tfidf\", TfidfTransformer(use_idf = True))\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "vpcOmINsyEIn"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imports_corpus_train_transformed = imports_featurizer.fit_transform(imports_corpus_train)"
      ],
      "metadata": {
        "id": "ls5l7YRByFpm"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sect_name_train_transformed = sect_name_featurizer.fit_transform(sect_name_train)"
      ],
      "metadata": {
        "id": "I4PiogNlyHTW"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bước 7: Kết hợp các vector thuộc tính thành 1 mảng."
      ],
      "metadata": {
        "id": "bol74SMwyK_0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.sparse import hstack, csr_matrix\n"
      ],
      "metadata": {
        "id": "Z0GXwgh7yQec"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = hstack(\n",
        "    [\n",
        "        Ngram_feat_list_train,\n",
        "        imports_corpus_train_transformed,\n",
        "        sect_name_train_transformed,\n",
        "        csr_matrix(num_sect_train).transpose(),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "SV5Lqz3vyRvs"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bước 8: Huấn luyên bằng phân loại Random Forest cho tập train"
      ],
      "metadata": {
        "id": "Thq0FPI1yUQa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n"
      ],
      "metadata": {
        "id": "CL5uEgKSyaGc"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf = RandomForestClassifier(n_estimators = 100)\n",
        "clf = clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "-LsA9AzSyb2D"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bước 9: Thu thập các thuộc tính của tập test, giống như tập huấn luyện"
      ],
      "metadata": {
        "id": "vIxYuQOXygLV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import_corpus_test = []\n",
        "num_sect_test = []\n",
        "sect_names_test = []\n",
        "Ngram_feat_list_test = []\n",
        "\n",
        "y_test = []"
      ],
      "metadata": {
        "id": "KiGwCzsSyjit"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(samples_test)):\n",
        "  test = samples_test[i]\n",
        "  try:\n",
        "    # Get all required parameters with predefined functions\n",
        "    # The input when getting N-grams features is still \"sample\"\n",
        "    Ngram_features = get_Ngrams_features_from_samples(sample, K1_most_common_Ngrams_list)\n",
        "    pe = pefile.PE(test) # Get test PE file\n",
        "    imports = get_imports(pe)\n",
        "    n_sections = len(pe.sections)\n",
        "    sec_names = get_section_names(pe)\n",
        "\n",
        "    # Put above value into lists\n",
        "    import_corpus_test.append(imports)\n",
        "    num_sect_test.append(n_sections)\n",
        "    sect_names_test.append(sec_names)\n",
        "    Ngram_feat_list_test.append(Ngram_features)\n",
        "\n",
        "    # Target train\n",
        "    y_test.append(target_test[i])\n",
        "  except Exception as e:\n",
        "    print(sample + \":\")\n",
        "    print(e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q3CyEu19ymV1",
        "outputId": "de6984ae-eb14-4752-b524-ee8c53bcb29c"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Benign PE Samples/HxOutlook.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/Benign PE Samples/HxOutlook.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/Benign PE Samples/HxOutlook.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/Benign PE Samples/HxOutlook.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/Benign PE Samples/HxOutlook.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/Benign PE Samples/HxOutlook.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/Benign PE Samples/HxOutlook.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/Benign PE Samples/HxOutlook.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/Benign PE Samples/HxOutlook.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/Benign PE Samples/HxOutlook.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/Benign PE Samples/HxOutlook.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/Benign PE Samples/HxOutlook.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/Benign PE Samples/HxOutlook.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/Benign PE Samples/HxOutlook.exe:\n",
            "'DOS Header magic not found.'\n",
            "/content/Benign PE Samples/HxOutlook.exe:\n",
            "'DOS Header magic not found.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bước 10: Chuyển đổi vector từ thuộc tính test, và kiểm tra kết quả của trình phân loại."
      ],
      "metadata": {
        "id": "VO0eIQd4zdP8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import_corpus_test_transformed = imports_featurizer.transform(import_corpus_test)"
      ],
      "metadata": {
        "id": "l2IWevvuyoO-"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sect_names_test_transformed = imports_featurizer.transform(sect_names_test)"
      ],
      "metadata": {
        "id": "QRr8jQvEyqGA"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = hstack(\n",
        "    [\n",
        "        Ngram_feat_list_test,\n",
        "        import_corpus_test_transformed,\n",
        "        sect_names_test_transformed,\n",
        "        csr_matrix(num_sect_test).transpose()\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "czpkqrptzRmU"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The score of our classifier is as follow: \")\n",
        "print(clf.score(X_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0EJU_xKYzTbD",
        "outputId": "dc5d3e12-d59d-459a-fcc7-81d3f6e05905"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The score of our classifier is as follow: \n",
            "0.984375\n"
          ]
        }
      ]
    }
  ]
}